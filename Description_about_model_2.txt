1> Description about the accuracy and loss graphs :-

The accuracy plot illustrates how the predictive performance of the model varies as it is trained. The x-axis (epochs) represents how many times the learning algorithm has cycled through the full training set. The y-axis (accuracy) is the proportion of accurate predictions. During the initial epochs, both the training and validation accuracy curves climb rapidly as the model begins to identify simple and general patterns in data. In a normal training process, the curve of validation accuracy will mimic the trend of the training accuracy curve, paralleling it with minimal disparity. Nonetheless, if the training accuracy consistently rises towards 1.0 (100%) while the validation accuracy plateaus or drops, then overfitting is evident. Overfitting occurs when the model is memorizing certain patterns in the training set, such as noise and outliers, rather than learning patterns that can be applied to new data.

The loss graph provides another perspective by exhibiting how far the predictions of the model are away from the real values over time. The epochs are plotted along the horizontal axis, and the vertical axis indicates the loss value, computed by the chosen loss function, here being categorical cross-entropy. Both training and validation loss values will be quite high at the beginning of training since the model parameters are initialized randomly and the predictions made by them will be incorrect. As training progresses, the loss decreases drastically in the initial epochs as the model rapidly adapts to the most obvious identifying characteristics. Both training and validation loss should decrease continuously as training continues. If, however, the training loss keeps falling while the validation loss plateaus and begins to climb, it once again indicates overfitting. This indicates the learning of the model is getting too specific to the training set.

For the suggested CNN + MobileNetV2 + Random Forest ensemble model, the training accuracy increases rapidly and saturates at around 91%, whereas the validation accuracy remains significantly lower and plateaus at around 75–85%. This difference between the two accuracy plots firmly indicates overfitting. The loss plots are similar too—training loss decreases uniformly throughout all the epochs, whereas validation loss is at a minimum for some point and subsequently increases in subsequent epochs. That contrast reflects that even though the model continues to improve on the training data, its accuracy on new validation data decreases due to bad generalization. This problem can be caused by a number of reasons such as class imbalance in the HAM10000 dataset, where the dominant majority class is melanocytic nevi, and the model becomes biased towards it, and the small number of samples for the rare classes, which hinders the model from learning their specific characteristics.


2> Description about the comparison table about different models :-

The comparison table presents a comprehensive comparison of the suggested CNN + MobileNetV2 + Random Forest ensemble model with various high-ranking models published in the literature for skin disease classification. Past studies have shown that deep learning, and more specifically, convolutional neural networks (CNNs) and ensembles, can match or even exceed the diagnostic accuracy of skilled dermatologists. For example, Esteva et al. trained a deep CNN on a very large dataset and reached dermatologist-level performance with around 66% accuracy for a nine-class classification task. Haenssle et al. pitted a CNN against 58 dermatologists directly in the binary melanoma-versus-nevus classification problem, demonstrating that the CNN performed better than the majority of dermatologists, with significantly higher sensitivity and specificity. Brinker et al. took this analysis further to 157 dermatologists, where their CNN performed better than 136 of them, further substantiating the promise of deep learning for the automated analysis of skin lesions. Likewise, Codella et al. applied an ensemble of several CNNs and showed enhanced performance compared to single CNN models, achieving a 76% accuracy for melanoma detection.

Unlike most of these earlier researches that mainly addressed binary classification problems like melanoma detection, the model presented herein solves a full seven-class classification issue based on the HAM10000 dataset, encompassing a range of malignant and benign skin diseases. By utilizing transfer learning from MobileNetV2, the model has access to a strong feature extractor pre-trained on the large-scale ImageNet dataset and is able to learn complex patterns of lesions with fewer training epochs. The deep features are then fed into both Softmax classifier and Random Forest classifier, and their predictions are ensembled using majority voting. This ensemble strategy successfully combines the power of deep learning with the interpretability and strength of conventional ensemble techniques, minimizing overfitting and enhancing classification stability.

The performance indicates that the hybrid model proposed in this work achieves a training accuracy of about 91%, which is better than the accuracies presented in the benchmarked studies. This improvement in performance is due to a combination of ensemble decision-making and deep transfer learning, together with the capacity of the model to process all seven disease categories at once. Additionally, the architecture of the proposed model is conducive to effective training and deployment, making it ideal for incorporation into web-based diagnostic software for clinical applications, especially in resource-constrained environments where the availability of dermatologists is limited. In general, the comparison table indicates that through the use of contemporary transfer learning architectures and ensemble classification methods, it is feasible to obtain substantial performance gains in multiclass skin disease classification relative to previous state-of-the-art models.


3> Contribution made in this paper :-

1.Construction of a Hybrid Deep Learning Model – Created and deployed a new ensemble design combining MobileNetV2 transfer learning with a Random Forest classifier, taking advantage of both deep feature extraction and classical ensemble learning to better classify skin disease.

2.Holistic Seven-Class Classification – Solved a multiclass skin disease classification task with the HAM10000 dataset, addressing seven separate benign and malignant lesion classes instead of just binary melanoma recognition like most prior research.

3.Ensemble Majority Voting Integration – Introduced a two-path classification framework that amalgamates predictions from the Softmax output of the CNN and the Random Forest classifier through majority voting, making predictions more robust and less model-biased.

4.Clinical Deployment Framework on the Web – Described a Flask-based web application that supports real-time image upload, classification, and treatment recommendation, facilitating viable deployment within resource-constrained healthcare environments.

5.Comparative Analysis with State-of-the-Art Models – Performed a thorough comparison with other deep learning methods in the literature and illustrated that the proposed solution attains greater training accuracy (~91%) and still has comparable performance in multiple classes.

